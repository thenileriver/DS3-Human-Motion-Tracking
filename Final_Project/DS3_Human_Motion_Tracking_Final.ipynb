{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade677dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2 as cv\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.models as models\n",
    "import torchvision.utils\n",
    "import time\n",
    "import wandb\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f43dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def Crop(self, image, x_coords, y_coords):    \n",
    "        x1 = x_coords.min() - 20\n",
    "        x2 = x_coords.max() + 20\n",
    "        y1 = y_coords.max() + 20\n",
    "        y2 = y_coords.min() - 20\n",
    "        \n",
    "        image = TF.crop(image, int(y2), int(x1), int(y1-y2), int(x2-x1))\n",
    "        return image, y2, x1\n",
    "    def Resize(self, image, img_size):\n",
    "        image = TF.resize(image, img_size)\n",
    "        newSize = image.size\n",
    "        return image, newSize\n",
    "    def ChangeCoords(self, initialSize, newSize, x_coords, y_coords):\n",
    "        Xratio = newSize[0]/initialSize[0]\n",
    "        Yratio = newSize[1]/initialSize[1]\n",
    "        \n",
    "        for i in range(0, len(x_coords)):\n",
    "            x_coords[i] = x_coords[i] * Xratio\n",
    "            y_coords[i] = y_coords[i] * Yratio\n",
    "        return x_coords, y_coords\n",
    "    def CropCoords(self, image, top, left, x_coords, y_coords):\n",
    "        for i in range(0, len(x_coords)):\n",
    "            x_coords[i] = x_coords[i] - left\n",
    "            y_coords[i] = y_coords[i] - top\n",
    "        return x_coords, y_coords\n",
    "    def rotate_image_and_landmarks(self, image, landmarks, angle):       \n",
    "        landmarks = np.array(landmarks).reshape(-1, 2)\n",
    "        image_shape = image.shape[-2:]\n",
    "        center = (image_shape[1] / 2, image_shape[0] / 2)\n",
    "        pil_image = TF.to_pil_image(image)\n",
    "        rotated_image = TF.rotate(pil_image, angle, center=center)\n",
    "        translated_landmarks = landmarks - center\n",
    "        angle_rad = np.radians(-angle)\n",
    "        rotation_matrix = np.array([[np.cos(angle_rad), -np.sin(angle_rad)],\n",
    "                                    [np.sin(angle_rad), np.cos(angle_rad)]])\n",
    "        rotated_landmarks = np.dot(translated_landmarks, rotation_matrix.T)\n",
    "        rotated_landmarks = rotated_landmarks + center\n",
    "        rotated_image = TF.to_tensor(rotated_image)\n",
    "        rotated_landmarks = rotated_landmarks.reshape(-1)\n",
    "        return rotated_image, rotated_landmarks\n",
    "    def mirror_image_and_landmarks(self, image, landmarks):\n",
    "        width = image.shape[2]\n",
    "        mirrored_image = torch.flip(image, [2])\n",
    "        mirrored_landmarks = landmarks.copy()\n",
    "        mirrored_landmarks[0::2] = width - landmarks[0::2]\n",
    "        return mirrored_image, mirrored_landmarks\n",
    "    def cutout(self, image_tensor, mask_size):\n",
    "        _, height, width = image_tensor.shape\n",
    "        mask_value = torch.mean(image_tensor)\n",
    "\n",
    "        top = random.randint(0, height - mask_size)\n",
    "        left = random.randint(0, width - mask_size)\n",
    "        bottom = top + mask_size\n",
    "        right = left + mask_size\n",
    "\n",
    "        image_tensor[:, top:bottom, left:right] = mask_value\n",
    "\n",
    "        return image_tensor\n",
    "    def __call__(self, img, x_coords, y_coords):\n",
    "        img = Image.fromarray(img)\n",
    "        img, top, left = self.Crop(img, x_coords, y_coords)\n",
    "        cropSize = img.size\n",
    "        x_coords, y_coords = self.CropCoords(img, top, left, x_coords, y_coords)\n",
    "        img, newSize = self.Resize(img, (224, 224))\n",
    "        x_coords, y_coords = self.ChangeCoords(cropSize, newSize, x_coords, y_coords)\n",
    "        img = TF.to_grayscale(img, 1)\n",
    "        img = TF.to_tensor(img)\n",
    "        #########################################\n",
    "        #img = TF.normalize(img, [0.5], [0.5])  #\n",
    "        #########################################\n",
    "        # Images look really wonky when normalized, will look into it\n",
    "        landmarks = np.array([])\n",
    "        for i in range(0, 16):\n",
    "            landmarks = np.append(landmarks, x_coords[i])\n",
    "            landmarks = np.append(landmarks, y_coords[i])\n",
    "        \n",
    "        was_rotated = False\n",
    "        was_mirrored = False\n",
    "        \n",
    "        if random.uniform(0, 1) > 0.5:\n",
    "            angle = 10\n",
    "            img, landmarks = self.rotate_image_and_landmarks(img, landmarks, angle)\n",
    "            was_rotated = True\n",
    "        if random.uniform(0, 1) > 0.5:\n",
    "            img, landmarks = self.mirror_image_and_landmarks(img, landmarks)\n",
    "            was_mirrored = True\n",
    "        if random.uniform(0, 1) > 0.5:\n",
    "            img = self.cutout(img, 30)\n",
    "        \n",
    "        landmarks_tensor = torch.tensor(landmarks, dtype=torch.float32)\n",
    "        \n",
    "        return img, landmarks_tensor, cropSize, left, top, was_rotated, was_mirrored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f857d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Body_Dataset():\n",
    "    def __init__(self, df, root_dir, transform = None):\n",
    "        self.annotations = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, str(self.annotations.iloc[index, 1]))\n",
    "        image = cv.imread(img_path)\n",
    "        landmarks = self.annotations.iloc[index, 2:-3]\n",
    "        x_coords = np.array([])\n",
    "        y_coords = np.array([])\n",
    "        for i in range(0, 32, 2):\n",
    "            x_coords = np.append(x_coords, landmarks[i])\n",
    "            y_coords = np.append(y_coords, landmarks[i+1])\n",
    "        x_coords_tensor = torch.tensor(x_coords, dtype=torch.float32)\n",
    "        y_coords_tensor = torch.tensor(y_coords, dtype=torch.float32)\n",
    "        if self.transform:\n",
    "            image, landmarks, cropSize, x, y, was_rotated, was_mirrored = self.transform(image, x_coords_tensor, y_coords_tensor)\n",
    "        return image, landmarks, cropSize, x, y, was_rotated, was_mirrored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02873bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.getsize('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2603ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Hyper Paramaters\n",
    "num_classes = 32\n",
    "num_epochs = 60\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "error = 2\n",
    "\n",
    "#Get Rid of -1 in DS\n",
    "bruh = pd.read_csv(\"MPII_Human_Pose.csv\")\n",
    "filtered_df = bruh[~(bruh == -1).any(axis=1)]\n",
    "filtered_df\n",
    "\n",
    "\n",
    "#Load Data\n",
    "dataset = Body_Dataset(df = filtered_df, root_dir = 'images', transform = Transform())\n",
    "\n",
    "#\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [10000, 1231])\n",
    "train_loader = DataLoader(dataset= train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset= test_dataset, batch_size = batch_size, shuffle = True)\n",
    "images, landmarks, size, x_test, y_test, was_rotated, was_mirrored = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [landmarks[0][0].item(), landmarks[0][2].item(), landmarks[0][4].item(), landmarks[0][6].item(), landmarks[0][8].item(), landmarks[0][10].item(), landmarks[0][12].item(), landmarks[0][14].item(), landmarks[0][16].item(), landmarks[0][18].item(), landmarks[0][20].item(), landmarks[0][22].item(), landmarks[0][24].item(), landmarks[0][26].item(), landmarks[0][28].item(), landmarks[0][30].item()]\n",
    "y = [landmarks[0][1].item(), landmarks[0][3].item(), landmarks[0][5].item(), landmarks[0][7].item(), landmarks[0][9].item(), landmarks[0][11].item(), landmarks[0][13].item(), landmarks[0][15].item(), landmarks[0][17].item(), landmarks[0][19].item(), landmarks[0][21].item(), landmarks[0][23].item(), landmarks[0][25].item(), landmarks[0][27].item(), landmarks[0][29].item(), landmarks[0][31].item()]\n",
    "\n",
    "def imshow(img, x, y):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.scatter(x, y)\n",
    "    plt.show()\n",
    "\n",
    "print(was_rotated)\n",
    "print(was_mirrored)\n",
    "imshow(torchvision.utils.make_grid(images), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ddd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self,num_classes=32):\n",
    "        super().__init__()\n",
    "        self.model_name='resnet101'\n",
    "        self.model=models.resnet101()\n",
    "        self.model.conv1=nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.model.fc=nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.model(x)\n",
    "        return x\n",
    "\n",
    "model = Network().to(device)\n",
    "\n",
    "#Loss and Optimizer functions\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "loss_min = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f114e759",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1,num_epochs+1): #epoch is how many times you go through the dataset\n",
    "    start_time = time.time()\n",
    "    loss_train = 0\n",
    "    loss_valid = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "    n_total_steps = len(train_loader)\n",
    "    for step in range(1,len(train_loader)+1):  #going through the dataset\n",
    "    \n",
    "        images, landmarks, Size, x, y, was_rotated, was_mirrored = next(iter(train_loader))\n",
    "        \n",
    "        images = images.to(device)\n",
    "        landmarks = landmarks.view(landmarks.size(0),-1).to(device)\n",
    "        \n",
    "        predictions = model(images)\n",
    "        \n",
    "        # clear all the gradients before calculating them\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # find the loss for the current step\n",
    "        loss_train_step = criterion(predictions, landmarks)\n",
    "        \n",
    "        # calculate the gradients\n",
    "        loss_train_step.backward()\n",
    "        \n",
    "        # update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_train += loss_train_step.item()\n",
    "        running_loss = loss_train/step       \n",
    "        \n",
    "        if step % 100 == 0:\n",
    "            print(f'Running Training Loss {step}/{n_total_steps}: {running_loss}')\n",
    "    \n",
    "    model.eval() \n",
    "    with torch.no_grad():\n",
    "        n_total_steps = len(test_loader)\n",
    "        n_samples = batch_size * num_classes\n",
    "        running_percent = 0\n",
    "        counter = 0\n",
    "        for step in range(1,len(test_loader)+1):\n",
    "            \n",
    "            images, landmarks, Size, x, y, was_rotated, was_mirrored = next(iter(test_loader))\n",
    "        \n",
    "            images = images.to(device)\n",
    "            landmarks = landmarks.view(landmarks.size(0),-1).to(device)\n",
    "        \n",
    "            predictions = model(images)\n",
    "\n",
    "            # find the loss for the current step\n",
    "            loss_valid_step = criterion(predictions, landmarks)\n",
    "\n",
    "            loss_valid += loss_valid_step.item()\n",
    "            running_loss = loss_valid/step\n",
    "            \n",
    "            if step % 100 == 0:\n",
    "                print(f'Running Validation Loss {step}/{n_total_steps}: {running_loss}')\n",
    "           \n",
    "            for j in range(0, batch_size):\n",
    "                width = Size[0][j]\n",
    "                height = Size[1][j]\n",
    "                Xratio = width/224\n",
    "                Yratio = height/224\n",
    "                \n",
    "                n_correct = 0\n",
    "                accuracy = 0\n",
    "                percent = 0\n",
    "                \n",
    "                x_coord = []\n",
    "                y_coord = []\n",
    "                \n",
    "                \n",
    "                if(was_mirrored == True):\n",
    "                    width = 224\n",
    "                    temp1 = np.array([x.item() for x in landmarks[j]])\n",
    "                    mirrored_landmarks = temp1.copy()\n",
    "                    mirrored_landmarks[0::2] = width - temp1[0::2]\n",
    "                    tensor_shape = (1, len(mirrored_landmarks))\n",
    "                    landmarks = torch.tensor(mirrored_landmarks, device='cuda:0').reshape(tensor_shape)\n",
    "                    \n",
    "                    \n",
    "                    temp2 = np.array([x.item() for x in predictions[j]])\n",
    "                    mirrored_predictions = temp2.copy()\n",
    "                    mirrored_predictions[0::2] = width - temp2[0::2]\n",
    "                    tensor_shape = (1, len(mirrored_predictions))\n",
    "                    predictions = torch.tensor(mirrored_predictions, device='cuda:0').reshape(tensor_shape)\n",
    "                \n",
    "                if(was_rotated == True):\n",
    "                    temp1 = np.array([x.item() for x in landmarks[j]])\n",
    "                    landmarks = np.array(temp1).reshape(-1, 2)\n",
    "                    image_shape = [224, 224]\n",
    "                    center = (image_shape[1] / 2, image_shape[0] / 2)\n",
    "                    translated_landmarks = landmarks - center\n",
    "                    angle_rad = np.radians(10)\n",
    "                    rotation_matrix = np.array([[np.cos(angle_rad), -np.sin(angle_rad)],\n",
    "                                                [np.sin(angle_rad), np.cos(angle_rad)]])\n",
    "                    rotated_landmarks = np.dot(translated_landmarks, rotation_matrix.T)\n",
    "                    rotated_landmarks = rotated_landmarks + center\n",
    "                    rotated_landmarks = rotated_landmarks.reshape(-1)\n",
    "                    tensor_shape = (1, len(rotated_landmarks))\n",
    "                    landmarks = torch.tensor(rotated_landmarks, device='cuda:0').reshape(tensor_shape)\n",
    "                    \n",
    "                    temp2 = np.array([x.item() for x in predictions[j]])\n",
    "                    predictions = np.array(temp2).reshape(-1, 2)\n",
    "                    image_shape = [224, 224]\n",
    "                    center = (image_shape[1] / 2, image_shape[0] / 2)\n",
    "                    translated_predictions = predictions - center\n",
    "                    rotation_matrix = np.array([[np.cos(angle_rad), -np.sin(angle_rad)],\n",
    "                                                [np.sin(angle_rad), np.cos(angle_rad)]])\n",
    "                    rotated_predictions = np.dot(translated_predictions, rotation_matrix.T)\n",
    "                    rotated_predictions = rotated_predictions + center\n",
    "                    rotated_predictions = rotated_predictions.reshape(-1)\n",
    "                    tensor_shape = (1, len(rotated_predictions))\n",
    "                    predictions = torch.tensor(rotated_predictions, device='cuda:0').reshape(tensor_shape)\n",
    "                \n",
    "                \n",
    "                for i in range(0, 32):\n",
    "                    if i%2 == 0:\n",
    "                        landmarks[j][i] = landmarks[j][i] * Xratio\n",
    "                        landmarks[j][i] = landmarks[j][i] + x[j]\n",
    "                        x_coord.append(landmarks[j][i])\n",
    "                        predictions[j][i] = predictions[j][i] * Xratio\n",
    "                        predictions[j][i] = predictions[j][i] + x[j]\n",
    "                        \n",
    "                    else:\n",
    "                        landmarks[j][i] = landmarks[j][i] * Yratio\n",
    "                        landmarks[j][i] = landmarks[j][i] + y[j]\n",
    "                        y_coord.append(landmarks[j][i])\n",
    "                        predictions[j][i] = predictions[j][i] * Yratio\n",
    "                        predictions[j][i] = predictions[j][i] + y[j]\n",
    "                    validation = predictions[j][i].item() - landmarks[j][i].item()\n",
    "                    if validation > 0:\n",
    "                        if validation <= error:\n",
    "                            n_correct = n_correct + 1\n",
    "                    if validation < 0:\n",
    "                        if validation >= -error:\n",
    "                            n_correct = n_correct + 1\n",
    "                accuracy = n_correct/n_samples\n",
    "                percent = 100 * accuracy\n",
    "                running_percent = running_percent + percent\n",
    "    average_percent = running_percent/len(test_loader)\n",
    "    loss_train /= len(train_loader)\n",
    "    loss_valid /= len(test_loader)\n",
    "    \n",
    "    acc = average_percent/100\n",
    "    \n",
    "    print('\\n--------------------------------------------------')\n",
    "    print(f'Average accuracy: {average_percent}%')\n",
    "    print('Epoch: {}  Train Loss: {:.4f}  Valid Loss: {:.4f}'.format(epoch, loss_train, loss_valid))\n",
    "    print(\"Total Elapsed Time : {} s\".format(time.time()-start_time))\n",
    "    print('--------------------------------------------------')\n",
    "\n",
    "    if loss_valid < loss_min:\n",
    "        loss_min = loss_valid\n",
    "        torch.save(model.state_dict(), './HumanPose_resnet101_60_epoch.pth') \n",
    "        print(\"\\nMinimum Validation Loss of {:.4f} at epoch {}/{}\".format(loss_min, epoch, num_epochs))\n",
    "        print('Model Saved\\n')\n",
    "    scheduler.step()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447efcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing model on images in their original state\n",
    "\n",
    "#The path of the model\n",
    "weights_path = 'HumanPose_resnet101_60_epoch.pth'\n",
    "\n",
    "#The path of the image being plotted on\n",
    "image_path = 'images/030424224.jpg'\n",
    "\n",
    "#These are the orignal landmarks for that image\n",
    "original_x = [324, 322, 293, 355, 401, 394, 324, 334, 338.6651, 360.3349, 363, 319, 298, 369, 390, 398]\n",
    "original_y = [406, 291, 262, 267, 292, 404, 265, 170, 157.2087, 97.7913, 167, 205, 168, 172, 221, 179]\n",
    "\n",
    "\n",
    "x = int(max(original_x) + 20)\n",
    "y = int(min(original_y) - 20)\n",
    "w = int(min(original_x) - 20)\n",
    "h = int(max(original_y) + 20)\n",
    "\n",
    "\n",
    "best_network = Network()\n",
    "best_network.load_state_dict(torch.load(weights_path, map_location=torch.device('cuda')), strict=False) \n",
    "best_network.eval()\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "display_image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "image = display_image[y:h, w:x]\n",
    "image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "height, width = image.shape\n",
    "Xratio = width/224\n",
    "Yratio = height/224\n",
    "image = TF.resize(Image.fromarray(image), size=(224, 224))\n",
    "image = TF.to_tensor(image)\n",
    "#image = TF.normalize(image, [0.5], [0.5])\n",
    "\n",
    "with torch.no_grad():\n",
    "    landmarks = best_network(image.unsqueeze(0))\n",
    "    \n",
    "for i in range(0, 32):\n",
    "    if i%2 == 0:\n",
    "        landmarks[0][i] = landmarks[0][i] * Xratio\n",
    "        landmarks[0][i] = landmarks[0][i] + w\n",
    "    else:\n",
    "        landmarks[0][i] = landmarks[0][i] * Yratio\n",
    "        landmarks[0][i] = landmarks[0][i] + y\n",
    "    \n",
    "plt.figure()\n",
    "plt.imshow(display_image)\n",
    "\n",
    "index = 0\n",
    "for i in range (0, 32, 2):\n",
    "    plt.scatter(landmarks[0][i], landmarks[0][i+1], c = 'c', s = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202598f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing output on images as they were fed into the model\n",
    "\n",
    "weights_path = 'HumanPose_resnet101_60_epoch.pth'\n",
    "image_path = 'images/094426649.jpg'\n",
    "\n",
    "original_x = [391, 418, 401, 410, 402, 359, 406, 396, 402.3095, 431.6905, 290, 332, 377, 415, 403, 394]\n",
    "original_y = [432, 346, 239, 237, 354, 300, 238, 158, 146.8833, 95.1167, 230, 200, 159, 156, 201, 238]\n",
    "\n",
    "\n",
    "x2 = int(max(original_x) + 20)\n",
    "y2 = int(min(original_y) - 20)\n",
    "x1 = int(min(original_x) - 20)\n",
    "y1 = int(max(original_y) + 20)\n",
    "\n",
    "best_network = Network()\n",
    "best_network.load_state_dict(torch.load(weights_path, map_location=torch.device('cuda')), strict=False) \n",
    "best_network.eval()\n",
    "\n",
    "image = cv.imread(image_path)\n",
    "image = Image.fromarray(image)\n",
    "image = TF.crop(image, int(y2), int(x1), int(y1-y2), int(x2-x1))\n",
    "image = TF.resize(image, size=(224, 224))\n",
    "image = TF.to_grayscale(image, 1)\n",
    "image = TF.to_tensor(image)\n",
    "#image = TF.normalize(image, [0.5], [0.5])\n",
    "\n",
    "\n",
    "def imshow(img, x, y):\n",
    "    #img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.scatter(x, y)\n",
    "    plt.show()\n",
    "    \n",
    "with torch.no_grad():\n",
    "    landmarks = best_network(image.unsqueeze(0))\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for i in range(len(landmarks[0])):\n",
    "    if i%2 == 0:\n",
    "        x.append(float(landmarks[0][i]))\n",
    "    else:\n",
    "        y.append(float(landmarks[0][i]))\n",
    "\n",
    "print(y)\n",
    "\n",
    "imshow(image, x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
